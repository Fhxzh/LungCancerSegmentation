{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "(308, 512, 512, 1)\n",
      "daten:\n",
      "2583\n",
      "2583\n",
      "269\n",
      "269\n",
      "706\n",
      "706\n",
      "datagen fit...\n",
      "datagen fit done.\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "Dice no np\n",
      "(?, ?, ?, ?)\n",
      "(?, 512, 512, 1)\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\")`\n",
      "/home/felix/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:149: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice no np\n",
      "(?, ?, ?, ?)\n",
      "(?, 512, 512, 1)\n",
      "---\n",
      "Fitting model...\n",
      "Epoch 1/25\n",
      "1268/1291 [============================>.] - ETA: 10s - loss: -0.1345 - dice_coef: 0.1345 - acc: 0.0000e+00 - precision: 189274.4570 - recall: 0.4232 - f1_score: 0.0172"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from itertools import izip\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "\n",
    "working_path = \"/home/felix/output/luna/subset0/\"\n",
    "\n",
    "\n",
    "\n",
    "K.set_image_dim_ordering('tf')  #Using Tensorflow\n",
    "\n",
    "img_cols = 512\n",
    "img_rows = 512\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    print('Dice no np')\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print('---')\n",
    "        \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_np(y_true,y_pred):\n",
    "    print('Dice NP')\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print('---')\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / (c2+ K.epsilon())\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / (c3+ K.epsilon())\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) /((precision + recall)+ K.epsilon())\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / (c2+ K.epsilon())\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    recall = c1 / (c3+ K.epsilon())\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(inputs)\n",
    "    conv1= BatchNormalization()\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv1)\n",
    "    conv1= BatchNormalization()\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    #\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    #\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_last')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv3)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2,up1],axis=3)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(up1)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv4)\n",
    "    #\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1,up2], axis=3)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(up2)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv5)\n",
    "    \n",
    "      \n",
    "    conv6 = Convolution2D(1, 1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(input=inputs, output=conv6)\n",
    "\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1.0e-4), loss=dice_coef_loss, metrics=[dice_coef, 'accuracy', precision, recall, f1_score])\n",
    "    return model\n",
    "\n",
    "def load_data():\n",
    "    print('-'*30)\n",
    "    \n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    working_path = \"/home/felix/output/luna/subset1/\"\n",
    "    #Loading traning data from subset 1 to 9\n",
    "    imgs_train=np.load(working_path+\"trainImages.npy\").astype(np.float32)\n",
    "    imgs_mask_train=np.load(working_path+\"trainMasks.npy\").astype(np.float32)\n",
    "    print(imgs_mask_train.shape)\n",
    "    for x in range(2,10):\n",
    "        working_path=\"/home/felix/output/luna/subset%d/\"% (x,)\n",
    "        imgs_train_temp = np.load(working_path+\"trainImages.npy\").astype(np.float32)\n",
    "        imgs_train=np.append(imgs_train,imgs_train_temp, axis=0)\n",
    "\n",
    "        imgs_mask_train_temp = np.load(working_path+\"trainMasks.npy\").astype(np.float32)\n",
    "        imgs_mask_train=np.append(imgs_mask_train,imgs_mask_train_temp, axis=0)\n",
    "       \n",
    "     \n",
    "    #Using the training data from subset 0 for validation\n",
    "    imgs_val =np.load(\"/home/felix/output/luna/subset0/trainImages.npy\").astype(np.float32)\n",
    "    imgs_mask_val=np.load(\"/home/felix/output/luna/subset0/trainMasks.npy\").astype(np.float32)\n",
    "    #imgs_val_temp = np.load(\"/home/felix/output/luna/subset9/trainImages.npy\").astype(np.float32)\n",
    "    #imgs_val=np.append(imgs_val,imgs_val_temp, axis=0)\n",
    "    #imgs_mask_val_temp = np.load(\"/home/felix/output/luna/subset9/trainMasks.npy\").astype(np.float32)\n",
    "    #imgs_mask_val=np.append(imgs_mask_val,imgs_mask_val_temp, axis=0)\n",
    "    \n",
    "    #Loading test data from subset 0-9\n",
    "    working_path = \"/home/felix/output/luna/subset0/\"\n",
    "    imgs_test =np.load(working_path+\"testImages.npy\").astype(np.float32)\n",
    "    imgs_mask_test_true =np.load(working_path+\"testMasks.npy\").astype(np.float32)\n",
    "     \n",
    "    for x in range(1,10):\n",
    "        working_path=\"/home/felix/output/luna/subset%d/\"% (x,)\n",
    "        imgs_temp= np.load(working_path+\"testImages.npy\").astype(np.float32)\n",
    "        imgs_test=np.append(imgs_test,imgs_temp, axis=0)\n",
    "        imgs_mask_temp = np.load(working_path+\"testMasks.npy\").astype(np.float32)\n",
    "        imgs_mask_test_true=np.append(imgs_mask_test_true,imgs_mask_temp, axis=0)\n",
    "    \n",
    "    \n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean  \n",
    "    imgs_train /= std\n",
    "\n",
    "    return imgs_train, imgs_mask_train, imgs_val, imgs_mask_val, imgs_test, imgs_mask_test_true\n",
    "\n",
    "    \n",
    "def train(use_existing):\n",
    "    \n",
    "    imgs_train, imgs_mask_train, imgs_val, imgs_mask_val, imgs_test, imgs_mask_test_true=load_data()\n",
    "    print('daten:')\n",
    "    print(len(imgs_train))\n",
    "    print (len(imgs_mask_train))\n",
    "    print(len(imgs_val))\n",
    "    print(len(imgs_mask_val))\n",
    "    print(len(imgs_test))\n",
    "    print (len(imgs_mask_test_true))\n",
    "    \n",
    "    \n",
    "    #Augmenting training images and masks\n",
    "    #  create two instances with the same arguments\n",
    "    # create dictionary with the input augmentation values\n",
    "    data_gen_args = dict(featurewise_center=True,\n",
    "                         featurewise_std_normalization=True,\n",
    "                         rotation_range=0,\n",
    "                         width_shift_range=0,\n",
    "                         height_shift_range=0,\n",
    "                         zoom_range=0.2, \n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip = True)\n",
    "    ## use this method with both images and masks\n",
    "    imgs_train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    #No alterations for validation set\n",
    "    #imgs_val_datagen= ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    masks_train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    #no alterations for validation set\n",
    "    #imgs_mask_val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    ## fit the augmentation model to the images and masks with the same seed\n",
    "    print('datagen fit...')\n",
    "    imgs_train_datagen.fit(imgs_train, augment=True, seed=seed)\n",
    "    masks_train_datagen.fit(imgs_mask_train, augment=True, seed=seed)\n",
    "    #imgs_val_datagen.fit(imgs_val, augment=False)\n",
    "    #imgs_mask_val_datagen.fit(imgs_mask_val, augment=False)\n",
    "    print('datagen fit done.')\n",
    "    ## set the parameters for the data to come from (images)\n",
    "    batch_size=2\n",
    "    imgs_train_generator = imgs_train_datagen.flow(\n",
    "        imgs_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=seed)\n",
    "    ## set the parameters for the data to come from (masks)\n",
    "    masks_train_generator= masks_train_datagen.flow(\n",
    "        imgs_mask_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=seed)\n",
    "    \n",
    "    #imgs_val_generator = imgs_val_datagen.flow(\n",
    "    #    imgs_val,\n",
    "    #    batch_size=batch_size,\n",
    "    #    shuffle=True,\n",
    "    #    seed=seed)\n",
    "    ## set the parameters for the data to come from (masks)\n",
    "    # masks_val_generator =  imgs_mask_val_datagen.flow(\n",
    "    #    imgs_mask_val,\n",
    "    #   batch_size=batch_size,\n",
    "    #  shuffle=True,\n",
    "    # seed=seed)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    #train_generator = zip(imgs_train_generator, masks_train_generator)\n",
    "    train_generator=izip(imgs_train_generator, masks_train_generator)\n",
    "    #val_generator = zip(imgs_val_generator, masks_val_generator)\n",
    "    #val_generator=izip(imgs_val_generator, masks_val_generator)\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    K.clear_session()\n",
    "    model = None\n",
    "    model = get_model()\n",
    "   \n",
    "    # Saving weights to unet.hdf5 at checkpoints\n",
    "    model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)\n",
    "    #\n",
    "    # Should we load existing weights? \n",
    "    # Set argument for call to train_and_predict to true at end of script\n",
    "    if use_existing:\n",
    "        model.load_weights('./unet.hdf5')  \n",
    "   \n",
    "   \n",
    "    print('Fitting model...')\n",
    "    #Early Stop when Validation does not decrease anymore\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    tbCallBack= keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=2, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "    \n",
    "    steps_per_epoch=len(imgs_train)/batch_size\n",
    "    #validation_steps=len(imgs_val)/batch_size\n",
    "    hist=model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=[imgs_val, imgs_mask_val],\n",
    "                    epochs=25,verbose=1,callbacks=[model_checkpoint, tbCallBack, early_stopping])\n",
    "    \n",
    "    '''\n",
    "    tbCallBack= keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=2, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "    hist=model.fit_generator(train_generator, steps_per_epoch=2000, epochs=50)\n",
    "    model.fit(imgs_train, imgs_mask_train,validation_split=0.1, batch_size=2, epochs=10, verbose=1, shuffle=True,\n",
    "              callbacks=[model_checkpoint, tbCallBack])\n",
    "    '''\n",
    "    print(hist.history)\n",
    "  \n",
    "\n",
    "    \n",
    "def predict(imgs_test, imgs_mask_test_true, model):\n",
    "    # loading best weights from training session\n",
    "    print('Loading saved weights...')\n",
    "    model.load_weights('./unet.hdf5')\n",
    "\n",
    "    print('Predicting masks on test data...')\n",
    "    num_test = len(imgs_test)\n",
    "    imgs_mask_test = np.ndarray([num_test,512,512,1],dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = model.predict([imgs_test[i:i+1]], verbose=0)[0]\n",
    "    print('PredMask: ')\n",
    "    print(imgs_mask_test.shape)\n",
    "    np.save('masksTestPredicted.npy', imgs_mask_test)\n",
    "    np.save('imagesTest.npy', imgs_test)\n",
    "    np.save('masksTestTrue.npy', imgs_mask_test_true)\n",
    "    \n",
    "    mean = 0.0\n",
    "    print('Mask_test_true: ')\n",
    "    print(imgs_mask_test_true[i][:, :, :].shape)\n",
    "    print('Mask_test_true: ')\n",
    "    print(imgs_mask_test_true[i].shape)\n",
    "    print('Mask_test_true: ')\n",
    "    print(imgs_mask_test_true[i,0].shape)\n",
    "    for i in range(num_test):\n",
    "        \n",
    "       # Channel last\n",
    "       # mean+=dice_coef_np(imgs_mask_test_true[i,0], imgs_mask_test[i,0])\n",
    "        mean+=dice_coef_np(imgs_mask_test_true[i], imgs_mask_test[i]) \n",
    "            \n",
    "    #mean=dice_coef(imgs_mask_test_true, imgs_mask_test)        \n",
    "    mean/=num_test\n",
    "    print(\"Mean Dice Coeff : \",mean)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for x in range(1):\n",
    "        train(False)\n",
    "        #imgs_train, imgs_mask_train, imgs_test, imgs_mask_test_true=load_data()\n",
    "        #model=None\n",
    "        #model=get_model()\n",
    "        #predict(imgs_test, imgs_mask_test_true, model)\n",
    "        #load_data()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
